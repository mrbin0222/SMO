{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMO for MoNuSeg or TNBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import build_sam, SamAutomaticMaskGenerator, SamPredictor, sam_model_registry\n",
    "from PIL import Image, ImageDraw\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "BICUBIC = InterpolationMode.BICUBIC\n",
    "\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import torchvision.datasets as dset\n",
    "from pycocotools.coco import COCO\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from yolo11.predict import predict_image\n",
    "from util.common import show_points2, convert_box_xywh_to_xyxy, segment_image\n",
    "from util.itm import retriev\n",
    "from util.loss import get_scores_loss,get_indices_of_values_above_threshold_2\n",
    "from util.cal_iou import calculate_metrics\n",
    "from util.cal_instance_iou import calculate_dice, calculate_miou\n",
    "from util.nms import NMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "sam_checkpoint = \"../checkpoints/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "print(f\"Loading time: {time.time()-time_start:.2f} s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MoNuSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path=\"../datasets/MoNuSeg/MoNuSegTestData/TissueImages/\"\n",
    "# liat all images\n",
    "img_res=os.listdir(im_path)\n",
    "img_res=[s for s in img_res if \"tif\" in s]\n",
    "img_res=sorted(img_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set one image\n",
    "index=0\n",
    "image_path=im_path+img_res[index]\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image0 = cv2.imread(image_path)\n",
    "image0 = cv2.cvtColor(image0, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SAM predictor\n",
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point layout prompts or Box layout prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout='point'\n",
    "layout='box'\n",
    "# mode='manual'\n",
    "mode='automatic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if layout=='point' and mode=='manual':\n",
    "    points_nuclei = []\n",
    "    with open('manual_points.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            x, y = map(float, line.strip().split())\n",
    "            points_nuclei.append(np.array([x, y]).reshape(1,2))\n",
    "\n",
    "if layout=='point' and mode=='automatic':\n",
    "    points_nuclei = []\n",
    "    model_path='../checkpoints/best.pt'\n",
    "    image_path_yolo='../datasets/MoNuSeg/MoNuSegTestData/test/images/'+img_res[index].split('tif')[0]+'png'\n",
    "    points_nuclei=predict_image(model_path,image_path_yolo,isbox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if layout=='box' and mode=='manual':\n",
    "    boxes = []\n",
    "    with open('manual_boxes.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            x1, y1, x2, y2 = map(float, line.strip().split())\n",
    "            boxes.append(np.array([x1, y1, x2, y2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if layout=='box' and mode=='automatic':\n",
    "    boxes=[]\n",
    "    model_path='../checkpoints/best.pt'\n",
    "    image_path_yolo='../datasets/MoNuSeg/MoNuSegTestData/test/images/'+img_res[index].split('tif')[0]+'png'\n",
    "    boxes=predict_image(model_path,image_path_yolo,isbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if layout=='point':\n",
    "    # prepare input points and labels\n",
    "    input_points = np.concatenate(points_nuclei)\n",
    "    points = torch.Tensor(input_points).to(predictor.device).unsqueeze(1).view(len(points_nuclei),1,2)\n",
    "    labels = torch.Tensor([int(l) for _, l in input_points]).to(predictor.device).unsqueeze(1).view(len(points_nuclei),1)\n",
    "    transformed_points = predictor.transform.apply_coords_torch(points, image.shape[:2])\n",
    "\n",
    "    # split points into batches, save memory\n",
    "    if transformed_points.shape[0] > 500:\n",
    "        cir = math.ceil(transformed_points.shape[0] / 500)\n",
    "    else:\n",
    "        cir = 1\n",
    "    # predict masks\n",
    "    mmm=[]\n",
    "    sss=[]\n",
    "    for pc in range(cir):\n",
    "        mp, sp, _ = predictor.predict_torch(\n",
    "                point_coords=transformed_points[pc*500:500*(pc+1)],\n",
    "                point_labels=labels[pc*500:500*(pc+1)],\n",
    "                boxes=None,\n",
    "                multimask_output=False,\n",
    "        )\n",
    "        mmm.append(mp.cpu().detach().numpy())\n",
    "        sss.append(sp.cpu().detach().numpy())\n",
    "    masks_p=np.concatenate(mmm,axis=0)\n",
    "    scores_p=np.concatenate(sss,axis=0)\n",
    "\n",
    "    # make masks\n",
    "    masks = []\n",
    "    for i,p in enumerate(zip(masks_p,scores_p)):\n",
    "        m = {}\n",
    "        m[\"segmentation\"] = p[0][0]\n",
    "        m[\"area\"] = int(p[0].sum())\n",
    "        a = np.where(p[0][0]==True)\n",
    "        m[\"bbox\"] = [a[1].min(), a[0].min(), a[1].max()-a[1].min(), a[0].max()-a[0].min()]\n",
    "        m[\"predicted_iou\"] = p[1][0].item()\n",
    "        m[\"point_coords\"] = points[i].cpu().detach().numpy().tolist()\n",
    "        m[\"stability_score\"] = p[1][0].item()\n",
    "        m[\"crop_box\"] = [0, 0, image.shape[1], image.shape[0]]\n",
    "        masks.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if layout=='box':\n",
    "    # prepare input boxes\n",
    "    input_boxes = torch.tensor([\n",
    "        boxes\n",
    "    ], device=predictor.device).squeeze()\n",
    "    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "\n",
    "    # split boxes into batches, save memory\n",
    "    if transformed_boxes.shape[0] > 500:\n",
    "        cir = math.ceil(transformed_boxes.shape[0] / 500)\n",
    "    else:\n",
    "        cir = 1\n",
    "    # predict masks\n",
    "    mmm=[]\n",
    "    sss=[]\n",
    "    for pc in range(cir):\n",
    "        mp, sp, _ = predictor.predict_torch(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                boxes=transformed_boxes[pc*500:500*(pc+1)],\n",
    "                multimask_output=False,\n",
    "        )\n",
    "        mmm.append(mp.cpu().detach().numpy())\n",
    "        sss.append(sp.cpu().detach().numpy())\n",
    "    masks_p=np.concatenate(mmm,axis=0)\n",
    "    scores_p=np.concatenate(sss,axis=0)\n",
    "\n",
    "    # make masks\n",
    "    masks = []\n",
    "    for i,p in enumerate(zip(masks_p,scores_p,boxes)):\n",
    "        m = {}\n",
    "        m[\"segmentation\"] = p[0][0]\n",
    "        m[\"area\"] = int(p[0].sum())\n",
    "        m[\"bbox\"] = [p[2][0],p[2][1],p[2][2]-p[2][0],p[2][3]-p[2][1]]\n",
    "        m[\"predicted_iou\"] = p[1][0].item()\n",
    "        m[\"stability_score\"] = p[1][0].item()\n",
    "        m[\"crop_box\"] = [0, 0, image.shape[1], image.shape[0]]\n",
    "        masks.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude large, small area items\n",
    "h0,w0,_=image0.shape\n",
    "s0=w0*h0\n",
    "alpha=0.00195\n",
    "gamma=2.8e-05\n",
    "h0,w0,_=image0.shape\n",
    "s0=w0*h0\n",
    "masks_f = []\n",
    "for i,p in enumerate(masks):\n",
    "    _,_,w,h = p[\"bbox\"]\n",
    "    if p[\"area\"] >= alpha*s0:\n",
    "        print(str(i)+': too big')\n",
    "        continue\n",
    "    elif p[\"area\"] <= gamma*s0:\n",
    "        print(str(i)+': too small')\n",
    "        continue\n",
    "    else:\n",
    "        masks_f.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks=masks_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out all masks\n",
    "image = Image.open(image_path)\n",
    "cropped_boxes = []\n",
    "\n",
    "for mask in masks:\n",
    "    # crop masks from input image\n",
    "    cropped_boxes.append(segment_image(image, mask[\"segmentation\"]).crop(convert_box_xywh_to_xyxy(mask[\"bbox\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP ITM Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = retriev(cropped_boxes, \"cell\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Loss and drop bad ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=get_scores_loss(masks,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = get_indices_of_values_above_threshold_2(scores, 0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_masks = []\n",
    "result_crops = []\n",
    "result_masks = []\n",
    "result_scores = []\n",
    "for seg_idx in indices:\n",
    "    segmentation_mask_image = Image.fromarray(masks[seg_idx][\"segmentation\"].astype('uint8') * 255)\n",
    "    result_crop = cropped_boxes[seg_idx]\n",
    "    segmentation_masks.append(segmentation_mask_image)\n",
    "    result_masks.append(masks[seg_idx])\n",
    "    result_scores.append(1-scores[seg_idx]) # 1-loss\n",
    "    result_crops.append(result_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate targets and scores\n",
    "t_scores=torch.tensor(result_scores)\n",
    "b = []\n",
    "for p in result_masks:\n",
    "    xyxy = convert_box_xywh_to_xyxy(p[\"bbox\"])\n",
    "    b.append(xyxy)\n",
    "t_boxes=torch.tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NMS(t_boxes,t_scores,0.9,GIoU=True,eps=1e-7)\n",
    "len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final results\n",
    "n_crops = []\n",
    "n_masks = []\n",
    "n_scores = []\n",
    "for i,v in enumerate(zip(result_crops,result_masks,result_scores)):\n",
    "    if i in list(np.array(n)):\n",
    "        n_crops.append(v[0])\n",
    "        n_masks.append(v[1])\n",
    "        n_scores.append(v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = Image.open(image_path)\n",
    "array0 = np.zeros(original_image.size,dtype=bool).T\n",
    "for p in n_masks:\n",
    "    array0 = np.logical_or(array0, p[\"segmentation\"])\n",
    "mat_array0 = np.uint8(array0)\n",
    "# Save segmentation results\n",
    "# tiff.imsave(str(\"./results/yolo11monuseg_mask_\"+img_res[index]), mat_array0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gt\n",
    "label_path=\"../datasets/MoNuSeg/MoNuSegTestData/labelcol/\"\n",
    "# list all images\n",
    "ann_img=os.listdir(label_path)\n",
    "ann_img=[s for s in ann_img if \"png\" in s]\n",
    "ann_img=sorted(ann_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_png=cv2.imread(label_path+ann_img[index])\n",
    "gray_gt=cv2.cvtColor(gt_png,cv2.COLOR_BGR2GRAY)\n",
    "mat_array_anno=cv2.threshold(gray_gt,200,1,cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE and IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=mat_array0.copy()\n",
    "gt=mat_array_anno.copy()\n",
    "gt=gt.reshape(1,gt.shape[0],gt.shape[1])\n",
    "res=res.reshape(1,res.shape[0],res.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice,iou=calculate_metrics(res,gt)\n",
    "dice,iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_miou_score = calculate_miou(res, gt, num_classes=2)\n",
    "print(f\"mIoU Score: {instance_miou_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
