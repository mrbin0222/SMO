{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import build_sam, SamAutomaticMaskGenerator, SamPredictor, sam_model_registry\n",
    "from PIL import Image, ImageDraw\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "BICUBIC = InterpolationMode.BICUBIC\n",
    "\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import torchvision.datasets as dset\n",
    "from pycocotools.coco import COCO\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from yolo11.predict import predict_image\n",
    "from util.common import show_points2, convert_box_xywh_to_xyxy, segment_image\n",
    "from util.itm import retriev\n",
    "from util.loss import get_scores_loss,get_indices_of_values_above_threshold_2\n",
    "from util.cal_iou import calculate_metrics\n",
    "from util.cal_instance_iou import calculate_dice, calculate_miou\n",
    "from util.nms import NMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "sam_checkpoint = \"../checkpoints/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "print(f\"Loading time: {time.time()-time_start:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../datasets/CTC/Fluo-N2DH-GOWT1/01/t002.tif\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image0 = cv2.imread(image_path)\n",
    "image0 = cv2.cvtColor(image0, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all masks way 1\n",
    "# masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all masks way 2 with parameters\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=20,\n",
    "    points_per_batch=128,\n",
    "    pred_iou_thresh=0.96,\n",
    "    stability_score_thresh=0.96,\n",
    "    stability_score_offset=1.0,\n",
    "    box_nms_thresh=0.7,\n",
    "    crop_n_layers=0,\n",
    "    crop_nms_thresh=0.7,\n",
    "    crop_overlap_ratio=512/1500,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    point_grids=None,\n",
    "    min_mask_region_area=1000,  # Requires open-cv to run post-processing\n",
    "    max_mask_region_area=0,\n",
    ")\n",
    "masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# check the number of masks\n",
    "print(len(masks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25: too big\n"
     ]
    }
   ],
   "source": [
    "# exclude large, small area items\n",
    "h0,w0,_=image0.shape\n",
    "s0=w0*h0\n",
    "alpha=4e-2\n",
    "gamma=1e-4\n",
    "h0,w0,_=image0.shape\n",
    "s0=w0*h0\n",
    "masks_f = []\n",
    "for i,p in enumerate(masks):\n",
    "    _,_,w,h = p[\"bbox\"]\n",
    "    if p[\"area\"] >= alpha*s0:\n",
    "        print(str(i)+': too big')\n",
    "        continue\n",
    "    elif p[\"area\"] <= gamma*s0:\n",
    "        print(str(i)+': too small')\n",
    "        continue\n",
    "    else:\n",
    "        masks_f.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks=masks_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out all masks\n",
    "image = Image.open(image_path)\n",
    "cropped_boxes = []\n",
    "\n",
    "for mask in masks:\n",
    "    # 把所有mask从输入图片中抠出来\n",
    "    cropped_boxes.append(segment_image(image, mask[\"segmentation\"]).crop(convert_box_xywh_to_xyxy(mask[\"bbox\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP ITM Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = retriev(cropped_boxes, \"mouse stem cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Loss and drop bad ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=get_scores_loss(masks,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = get_indices_of_values_above_threshold_2(scores, 0.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "segmentation_masks = []\n",
    "result_crops = []\n",
    "result_masks = []\n",
    "result_scores = []\n",
    "for seg_idx in indices:\n",
    "    segmentation_mask_image = Image.fromarray(masks[seg_idx][\"segmentation\"].astype('uint8') * 255)\n",
    "    result_crop = cropped_boxes[seg_idx]\n",
    "    segmentation_masks.append(segmentation_mask_image)\n",
    "    result_masks.append(masks[seg_idx])\n",
    "    result_scores.append(1-scores[seg_idx]) # 1-loss\n",
    "    result_crops.append(result_crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate targets and scores\n",
    "t_scores=torch.tensor(result_scores)\n",
    "b = []\n",
    "for p in result_masks:\n",
    "    xyxy = convert_box_xywh_to_xyxy(p[\"bbox\"])\n",
    "    b.append(xyxy)\n",
    "t_boxes=torch.tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = NMS(t_boxes,t_scores,0.8,GIoU=True,eps=1e-7)\n",
    "len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final results\n",
    "n_crops = []\n",
    "n_masks = []\n",
    "n_scores = []\n",
    "for i,v in enumerate(zip(result_crops,result_masks,result_scores)):\n",
    "    if i in list(np.array(n)):\n",
    "        n_crops.append(v[0])\n",
    "        n_masks.append(v[1])\n",
    "        n_scores.append(v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = Image.open(image_path)\n",
    "array0 = np.zeros(original_image.size,dtype=bool).T\n",
    "for p in n_masks:\n",
    "    array0 = np.logical_or(array0, p[\"segmentation\"])\n",
    "mat_array0 = np.uint8(array0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gt\n",
    "gt = tiff.imread(str(\"../datasets/CTC/Fluo-N2DH-GOWT1/01_ST/SEG/man_seg002.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt=np.where(gt>0,np.ones_like(gt),np.zeros_like(gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE and IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=mat_array0.copy()\n",
    "gt=gt.reshape(1,gt.shape[0],gt.shape[1])\n",
    "res=res.reshape(1,res.shape[0],res.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.978380519822726, 0.9576760612013341)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice,iou=calculate_metrics(res,gt)\n",
    "dice,iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mIoU Score: 0.9773\n"
     ]
    }
   ],
   "source": [
    "instance_miou_score = calculate_miou(res, gt, num_classes=2)\n",
    "print(f\"mIoU Score: {instance_miou_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
